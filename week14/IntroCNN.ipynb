{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Image Classification using Convolutional Neural Networks (CNNs)\n",
    "\n",
    "#### Objective:\n",
    "\n",
    "The objective of this exercise is to provide students with hands-on experience in building, training, and evaluating a Convolutional Neural Network (CNN) for image classification using the Caltech101 dataset. Students will learn the principles of CNNs, including convolutional layers, pooling layers, and fully connected layers, as well as techniques for data augmentation and model evaluation.\n",
    "\n",
    "#### Dataset:\n",
    "\n",
    "Caltech101: This dataset contains 101 categories of objects, with approximately 40 to 800 images per category. The images are of various sizes, but most are medium resolution."
   ],
   "id": "12fc448f412aaaf7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T17:16:56.470415Z",
     "start_time": "2024-07-24T17:16:49.027239Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Dataset Preparation:\n",
    "\n",
    "1. Download the Caltech101 dataset and organize it into training and testing sets.\n",
    "2. Apply data preprocessing techniques such as resizing images to a consistent size, normalizing pixel values, and data augmentation (rotation, scaling, flipping, etc.)."
   ],
   "id": "8240cdbcfcac3f73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T17:16:56.690625Z",
     "start_time": "2024-07-24T17:16:56.472747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(train_dataset, test_dataset), dataset_info = tfds.load(\n",
    "    name='caltech101:3.0.1',\n",
    "    split=['train[:80%]','test[:90%]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    data_dir='C:\\\\Users\\\\ivanc\\\\PycharmProjects\\\\scientificProject',\n",
    "    download=False\n",
    ")"
   ],
   "id": "1ed5adf225c74c10",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data loading:\n",
    "\n",
    "`tfds.load`: This function loads the specified dataset. Here, it's loading the 'caltech101' dataset with version '3.0.1'.\n",
    "\n",
    "`split=['train[:80%]','train[:20%]']`: The dataset is split into two parts: 80% for training and 20% for testing.\n",
    "\n",
    "`with_info=True`: This flag indicates that additional metadata about the dataset should be returned, such as the number of classes.\n",
    "\n",
    "`as_supervised=True`: This ensures that the data is returned as a tuple (image, label) rather than a dictionary. This format is typical for supervised learning tasks.\n",
    "\n",
    "`download=False`: This prevents the code from downloading the dataset if it is not already available locally."
   ],
   "id": "fe90019d233aded2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T17:16:56.800487Z",
     "start_time": "2024-07-24T17:16:56.693338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = dataset_info.features['label'].num_classes\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_image).shuffle(1000).batch(32)\n",
    "test_dataset = test_dataset.map(preprocess_image).batch(32)"
   ],
   "id": "aceb9cb7812306a3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data preprocessing:\n",
    "\n",
    "`tf.image.resize(image, (224, 224))`: Resizes each image to 224x224 pixels. This is a common size for CNN inputs, such as those used in models like VGG and ResNet.\n",
    "\n",
    "`tf.cast(image, tf.float32) / 255.0`: Converts the pixel values to float32 and normalizes them to the range [0, 1]. This normalization helps improve the convergence of neural networks during training."
   ],
   "id": "abe327348b55974d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T17:16:57.052332Z",
     "start_time": "2024-07-24T17:16:56.804810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ],
   "id": "d8175c8f607c86fb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model definition:\n",
    "\n",
    "`models.Sequential`: This specifies a linear stack of layers. The layers are added sequentially, meaning each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "`layers.Conv2D(32, (3, 3), activation='relu')`: This layer creates 32 filters, each of size 3x3, which convolve over the input image. The activation function used is ReLU (Rectified Linear Unit), which introduces non-linearity into the model.\n",
    "input_shape=(224, 224, 3): Specifies the input shape, where 224x224 is the image size and 3 is the number of color channels (RGB).\n",
    "\n",
    "`layers.MaxPooling2D((2, 2))`: This layer performs max pooling with a 2x2 filter, reducing the spatial dimensions (height and width) by half. It helps in reducing the computational complexity and the risk of overfitting by down-sampling the input.\n",
    "\n",
    "`layers.Conv2D(64, (3, 3), activation='relu')`: This layer increases the number of filters to 64, with each filter of size 3x3. This deeper layer can learn more complex features.\n",
    "\n",
    "`layers.Flatten()`: This layer flattens the 2D outputs from the previous layer into a 1D vector, preparing the data for the fully connected layers.\n",
    "\n",
    "`layers.Dense(128, activation='relu')`: A dense layer with 128 units and ReLU activation. Dense layers are fully connected, meaning each neuron in the layer receives input from all neurons in the previous layer. This layer helps in learning complex \n",
    "\n",
    "`layers.Dense(num_classes, activation='softmax')`: The output layer with a number of units equal to the number of classes (num_classes). The softmax activation function is used, which outputs a probability distribution over the classes, making it suitable for multi-class classification."
   ],
   "id": "aaf6c693741e3df7"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-24T17:16:57.054565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ],
   "id": "34a2fd13cd61fc53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/77 [===========>..................] - ETA: 19s - loss: 5.9035 - accuracy: 0.0171"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model compilation:\n",
    "\n",
    "`optimizer='adam'`: The Adam (Adaptive Moment Estimation) optimizer is used to adjust the model's weights during training. Adam is a popular choice because it combines the advantages of two other extensions of stochastic gradient descent: Adaptive Gradient Algorithm (AdaGrad) and Root Mean Square Propagation (RMSProp). It adapts the learning rate for each parameter, making the optimization process more efficient and potentially leading to faster convergence.\n",
    "\n",
    "`loss='sparse_categorical_crossentropy'`: This loss function is used for multi-class classification problems where the target labels are integers. In this case, the labels are provided as integers (e.g., 0, 1, 2, ...) rather than one-hot encoded vectors. The sparse categorical crossentropy computes the cross-entropy loss between the true labels and the predicted probabilities, which is suitable for multi-class classification tasks.\n",
    "\n",
    "`metrics=['accuracy']`: This specifies that accuracy will be tracked during training and evaluation. Accuracy is a common metric for classification tasks, representing the proportion of correctly predicted samples."
   ],
   "id": "e5c02970eb17a9e5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "num_params = model.count_params()\n",
    "print(f\"Number of trainable parameters in the model: {num_params}\")"
   ],
   "id": "b412fe568440dec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
   ],
   "id": "edbef9d5625f1d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "misclassified_images = []\n",
    "misclassified_labels = []\n",
    "for image, label in test_dataset:\n",
    "    predictions = model.predict(image)\n",
    "    predicted_label = np.argmax(predictions, axis=1)\n",
    "    misclassified_idx = np.where(predicted_label != label.numpy())[0]\n",
    "    for idx in misclassified_idx:\n",
    "        misclassified_images.append(image[idx])\n",
    "        misclassified_labels.append(predicted_label[idx])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(misclassified_images)):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(misclassified_images[i])\n",
    "    plt.title(f\"Predicted: {misclassified_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "386b7b78183be816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "niceclassified_images = []\n",
    "niceclassified_labels = []\n",
    "for image, label in test_dataset:\n",
    "    predictions = model.predict(image)\n",
    "    predicted_label = np.argmax(predictions, axis=1)\n",
    "    niceclassified_idx = np.where(predicted_label == label.numpy())[0]\n",
    "    for idx in niceclassified_idx:\n",
    "        niceclassified_images.append(image[idx])\n",
    "        niceclassified_labels.append(predicted_label[idx])\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i in range(len(niceclassified_images)):\n",
    "    plt.subplot(20, 20, i+1)\n",
    "    plt.imshow(niceclassified_images[i])\n",
    "    plt.title(f\"P: {niceclassified_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "a30065eebdc1298b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sample_image, _ = next(itertools.islice(iter(test_dataset), 0, 1))\n",
    "sample_image = sample_image[:1]\n",
    "\n",
    "activation_model = models.Model(inputs=model.input,\n",
    "                                outputs=[layer.output for layer in model.layers])\n",
    "# activation_model = models.Model(inputs=model.input, outputs=model.layers[4].output)\n",
    "activations = activation_model.predict(sample_image)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, activation in enumerate(activations):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    try:\n",
    "        plt.imshow(activation[0, :, :, 0], cmap='viridis')\n",
    "    except:\n",
    "        pass\n",
    "    plt.title(f\"Activation {i+1}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "5fa664b8e9eba3b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c80dbd1a83baf895",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
